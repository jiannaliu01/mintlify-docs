---
title: "FAQs"
description: "Common questions about Cardinal’s architecture, features, and workflows."
---

### What's your secret sauce?

We get this a lot, and even wrote a [blog about it](https://trycardinal.ai/blog/under-the-hood)!

--- 

### What if I have a really big PDF?

Yes — large PDFs are supported. You can upload via the **`/markdown`** endpoint using either:  
- **File upload** (`multipart/form-data`)  
- **File URL** (publicly accessible link)  

For very large files, we recommend using the `fileUrl` parameter so you don’t have to push hundreds of MBs over the wire.

---

### Where do results get stored?

By default, results are returned inline in the API response.  

---

### Do you support encrypted documents?

Yes — Cardinal supports encrypted documents using the pycryptodome library. If you need support for an encryption method we don’t currently cover, reach out at team@trycardinal.ai.

---

### Is there a retry mechanism?

Yes. Failed pages are reported in the response (`failed_pages`). You can retry only those pages rather than re-processing the entire document.

---

### Can I add enrichment prompts or additional context?

Yes — you can attach custom prompts or metadata for enrichment (currently in beta). For example, you can append descriptions to figures or map schema fields to your own ontology. This is especially useful in workflows like RAG or downstream classification.

If you’d like early access, contact us at team@trycardinal.ai.

---

### Do you handle flattened documents?

Yes. Even if the PDF is “flattened” (text embedded on top of an image or scanned forms), Cardinal extracts the text + bounding boxes and re-aligns them. Some fidelity may be reduced depending on scan quality.

---

### What about really long documents?

Cardinal automatically chunks long files and processes them in parallel. This lets us handle **hundreds of pages** per document while keeping latency manageable.  

---

### What if I have traffic spikes?

We support **autoscaling**. Large bursts of documents are automatically distributed across workers, so you don’t need to manage scaling yourself.


